{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LCn9RnY6-2e"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        ".getOrCreate()\n",
        "\n",
        "web_server_logs_df = spark.read \\\n",
        ".option('header', True) \\\n",
        ".csv('/content/web_server_logs.csv')\n",
        "\n",
        "web_server_logs_df = (web_server_logs_df\n",
        ".withColumn('timestamp', F.to_timestamp(col('timestamp'),\n",
        "            \"yyyy-MM-dd'T'HH:mm:ss.SSSSSS\"))\n",
        ".withColumn('date', F.to_date(col('timestamp')))\n",
        ".withColumn('response_size', col('response_size').cast('int'))\n",
        ".withColumn('response_code', col('response_code').cast('int'))\n",
        ")\n",
        "\n",
        "web_server_logs_df.createOrReplaceTempView('web_server_logs')\n",
        "\n",
        "query = \"\"\"\n",
        "        SELECT ip, COUNT(*) as request_count\n",
        "        FROM web_server_logs\n",
        "        GROUP BY ip\n",
        "        ORDER BY request_count DESC\n",
        "        LIMIT 10\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "query1 = \"\"\"\n",
        "         SELECT method, COUNT(*) as method_count\n",
        "         FROM web_server_logs\n",
        "         GROUP BY method\n",
        "         ORDER BY method_count DESC\n",
        "         \"\"\"\n",
        "\n",
        "query2 = \"\"\"\n",
        "         SELECT date, SUM(response_size) as total_response_size\n",
        "         FROM web_server_logs\n",
        "         WHERE response_code = 404\n",
        "         GROUP BY date\n",
        "         ORDER BY date DESC\n",
        "         \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cnt_404 = web_server_logs_df.filter(F.col('response_code') == 404).count()\n",
        "\n",
        "\n",
        "\n",
        "print('Top 10 active IP addresses:')\n",
        "spark.sql(query).show(truncate=False)\n",
        "print('Request countby HTTP method:')\n",
        "spark.sql(query1).show(truncate=False)\n",
        "print(f'Number of 404 response codes: {cnt_404}')\n",
        "print('Total response size by day:')\n",
        "spark.sql(query2).show(truncate=False)"
      ]
    }
  ]
}